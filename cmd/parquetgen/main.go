package main

import (
	"flag"
	"fmt"
	"go/ast"
	"go/parser"
	"go/token"
	"log"
	"os"
	"text/template"
)

var (
	typ = flag.String("type", "", "type name")
	pkg = flag.String("package", "", "package name")
	pth = flag.String("input", "", "path to the go file that defines -type")
)

func main() {
	flag.Parse()

	i := input{
		Package: *pkg,
		Type:    *typ,
	}

	fields, err := getFields()
	if err != nil {
		log.Fatal(err)
	}

	i.Fields = formatFields(fields)

	tmpl, err := template.New("output").Parse(tpl)
	if err != nil {
		log.Fatal(err)
	}

	f, err := os.Create("parquet.go")
	if err != nil {
		log.Fatal(err)
	}

	err = tmpl.Execute(f, i)
	if err != nil {
		log.Fatal(err)
	}

	f.Close()
}

func formatFields(fields []field) []string {
	out := make([]string, len(fields))
	for i, f := range fields {
		out[i] = fmt.Sprintf(`%s(func(x %s) %s { return x.%s }, "%s"),`, f.FuncName, *typ, f.TypeName, f.FieldName, f.FieldName)
	}
	return out
}

func getFields() ([]field, error) {
	fset := token.NewFileSet()
	file, err := parser.ParseFile(fset, *pth, nil, 0)
	if err != nil {
		log.Fatal(err)
	}

	f := &finder{n: map[string]ast.Node{}}

	ast.Walk(visitorFunc(f.findTypes), file)

	if f.n == nil {
		return nil, fmt.Errorf("could not find %s", *typ)
	}

	fields, err := doGetFields(f.n)
	if err != nil {
		return nil, err
	}

	out := fields[*typ]
	for i, name := range getEmbeddedStructs(f.n[*typ]) {
		newFields := fields[name]
		out = append(out[:i], append(newFields, out[i:]...)...)
	}

	return out, nil
}

func getEmbeddedStructs(n ast.Node) []string {
	var out []string
	ast.Inspect(n, func(n ast.Node) bool {
		switch x := n.(type) {
		case *ast.Field:
			if len(x.Names) == 0 {
				out = append(out, fmt.Sprintf("%s", x.Type))
			}
		}
		return true
	})

	return out
}

func doGetFields(n map[string]ast.Node) (map[string][]field, error) {
	fields := map[string][]field{}
	for k, n := range n {
		ast.Inspect(n, func(n ast.Node) bool {
			switch x := n.(type) {
			case *ast.Field:
				if len(x.Names) == 1 {
					f := getField(x.Names[0].Name, x)
					fields[k] = append(fields[k], f)
				}
			}
			return true
		})
	}
	return fields, nil
}

func getField(name string, x ast.Node) field {
	var typ string
	var optional bool
	ast.Inspect(x, func(n ast.Node) bool {
		switch t := n.(type) {
		case *ast.StarExpr:
			optional = true
		case ast.Expr:
			s := fmt.Sprintf("%v", t)
			if s != name {
				typ = s
			}
		}
		return true
	})

	return field{FieldName: name, TypeName: getTypeName(typ, optional), FuncName: lookupType(typ, optional)}
}

func getTypeName(s string, optional bool) string {
	var star string
	if optional {
		star = "*"
	}
	return fmt.Sprintf("%s%s", star, s)
}

func lookupType(name string, optional bool) string {
	var op string
	if optional {
		op = "Optional"
	}
	switch name {
	case "int32":
		return fmt.Sprintf("NewInt32%sField", op)
	case "uint32":
		return fmt.Sprintf("NewUint32%sField", op)
	case "int64":
		return fmt.Sprintf("NewInt64%sField", op)
	case "uint64":
		return fmt.Sprintf("NewUint64%sField", op)
	case "float32":
		return fmt.Sprintf("NewFloat32%sField", op)
	case "float64":
		return fmt.Sprintf("NewFloat64%sField", op)
	case "bool":
		return fmt.Sprintf("NewBool%sField", op)
	case "string":
		return fmt.Sprintf("NewString%sField", op)
	}
	return ""
}

type visitorFunc func(n ast.Node) ast.Visitor

func (f visitorFunc) Visit(n ast.Node) ast.Visitor {
	return f(n)
}

type finder struct {
	n map[string]ast.Node
}

func (f *finder) findTypes(n ast.Node) ast.Visitor {
	switch n := n.(type) {
	case *ast.Package:
		return visitorFunc(f.findTypes)
	case *ast.File:
		return visitorFunc(f.findTypes)
	case *ast.GenDecl:
		if n.Tok == token.TYPE {
			return visitorFunc(f.findTypes)
		}
	case *ast.TypeSpec:
		f.n[n.Name.Name] = n
		return visitorFunc(f.findTypes)
	}

	return nil
}

type field struct {
	FieldName string
	TypeName  string
	FuncName  string

	structName string
}

type input struct {
	Package string
	Type    string
	Fields  []string
}

var tpl = `package {{.Package}}

// This code is generated by github.com/parsyl/parquet.
// It is advised that you shouldn't edit it.

import (
	"bytes"
	"encoding/binary"
	"io"

	"github.com/golang/snappy"
	"github.com/parsyl/parquet"
)

// ParquetWriter reprents a row group
type ParquetWriter struct {
	fields []Field

	newFields func() []Field
	len int

	// records are for subsequent chunks
	child *ParquetWriter

	// max is the number of Record items that can get written before
	// a new set of column chunks is written
	max int

	meta *parquet.Metadata
	w    *WriteCounter
}

func Fields() []Field {
	return []Field{ {{range .Fields}}
		{{.}}{{end}}
	}
}

func NewParquetWriter(w io.Writer, opts ...func(*ParquetWriter)) *ParquetWriter {
	p := &ParquetWriter{
		max:       1000,
		w:         &WriteCounter{w: w},
		fields:    Fields(),
		newFields: Fields,
	}

	for _, opt := range opts {
		opt(p)
	}

	if p.meta == nil {
		ff := Fields()
		schema := make([]parquet.Field, len(ff))
		for i, f := range ff {
			schema[i] = f.Schema()
		}
		p.meta = parquet.New(schema...)
	}

	return p
}

func withMeta(m *parquet.Metadata) func(*ParquetWriter) {
	return func(p *ParquetWriter) {
		p.meta = m
	}
}

// MaxPageSize is the maximum number of rows in each row groups' page.
func MaxPageSize(m int) func(*ParquetWriter) {
	return func(p *ParquetWriter) {
		p.max = m
	}
}

func (p *ParquetWriter) Write() error {
	if _, err := p.w.Write([]byte("PAR1")); err != nil {
		return err
	}

	for i, f := range p.fields {
		pos := p.w.n
		f.Write(p.w, p.meta, pos)

		for child := p.child; child != nil; child = child.child {
			pos := p.w.n
			child.fields[i].Write(p.w, p.meta, pos)
		}
	}

	if err := p.meta.Footer(p.w); err != nil {
		return err
	}

	_, err := p.w.Write([]byte("PAR1"))
	return err
}

func (p *ParquetWriter) Add(rec {{.Type}}) {
	if p.len == p.max {
		if p.child == nil {
			p.child = NewParquetWriter(p.w, MaxPageSize(p.max), withMeta(p.meta))
		}

		p.child.Add(rec)
		return
	}

	for _, f := range p.fields {
		f.Add(rec)
	}

	p.len++
}

type Field interface {
	Add(r {{.Type}})
	Write(w io.Writer, meta *parquet.Metadata, pos int) error
	Schema() parquet.Field
}

type RequiredNumField struct {
	vals []interface{}
	col  string
}

func (i *RequiredNumField) Write(w io.Writer, meta *parquet.Metadata, pos int) error {
	buf := bytes.Buffer{}
	wc := &WriteCounter{w: &buf}

	for _, i := range i.vals {
		if err := binary.Write(wc, binary.LittleEndian, i); err != nil {
			return err
		}
	}

	compressed := snappy.Encode(nil, buf.Bytes())
	if err := meta.WritePageHeader(w, i.col, pos, wc.n, len(compressed), len(i.vals)); err != nil {
		return err
	}

	_, err := io.Copy(w, bytes.NewBuffer(compressed))
	return err
}

type OptionalNumField struct {
	vals []interface{}
	defs []int64
	col  string
}

func (i *OptionalNumField) Write(w io.Writer, meta *parquet.Metadata, pos int) error {
	buf := bytes.Buffer{}
	wc := &WriteCounter{w: &buf}

	err := WriteLevels(wc, i.defs)
	if err != nil {
		return err
	}

	for _, i := range i.vals {
		if err := binary.Write(wc, binary.LittleEndian, i); err != nil {
			return err
		}
	}

	compressed := snappy.Encode(nil, buf.Bytes())
	if err := meta.WritePageHeader(w, i.col, pos, wc.n, len(compressed), len(i.defs)); err != nil {
		return err
	}

	_, err = io.Copy(w, bytes.NewBuffer(compressed))
	return err
}

type Uint32Field struct {
	RequiredNumField
	val func(r {{.Type}}) uint32
}

func NewUint32Field(val func(r {{.Type}}) uint32, col string) *Uint32Field {
	return &Uint32Field{
		val:              val,
		RequiredNumField: RequiredNumField{col: col},
	}
}

func (i *Uint32Field) Schema() parquet.Field {
	return parquet.Field{Name: i.col, Type: parquet.Uint32Type, RepetitionType: parquet.RepetitionRequired}
}

func (i *Uint32Field) Add(r {{.Type}}) {
	i.vals = append(i.vals, i.val(r))
}

type Uint32OptionalField struct {
	OptionalNumField
	val func(r {{.Type}}) *uint32
}

func NewUint32OptionalField(val func(r {{.Type}}) *uint32, col string) *Uint32OptionalField {
	return &Uint32OptionalField{
		val:              val,
		OptionalNumField: OptionalNumField{col: col},
	}
}

func (i *Uint32OptionalField) Schema() parquet.Field {
	return parquet.Field{Name: i.col, Type: parquet.Uint32Type, RepetitionType: parquet.RepetitionOptional}
}

func (i *Uint32OptionalField) Add(r {{.Type}}) {
	v := i.val(r)
	if v != nil {
		i.vals = append(i.vals, *v)
		i.defs = append(i.defs, 1)
	} else {
		i.defs = append(i.defs, 0)
	}
}

type Int32Field struct {
	RequiredNumField
	val func(r {{.Type}}) int32
}

func NewInt32Field(val func(r {{.Type}}) int32, col string) *Int32Field {
	return &Int32Field{
		val:              val,
		RequiredNumField: RequiredNumField{col: col},
	}
}

func (i *Int32Field) Schema() parquet.Field {
	return parquet.Field{Name: i.col, Type: parquet.Int32Type, RepetitionType: parquet.RepetitionRequired}
}

func (i *Int32Field) Add(r {{.Type}}) {
	i.vals = append(i.vals, i.val(r))
}

type Int32OptionalField struct {
	OptionalNumField
	val func(r {{.Type}}) *int32
}

func NewInt32OptionalField(val func(r {{.Type}}) *int32, col string) *Int32OptionalField {
	return &Int32OptionalField{
		val:              val,
		OptionalNumField: OptionalNumField{col: col},
	}
}

func (i *Int32OptionalField) Schema() parquet.Field {
	return parquet.Field{Name: i.col, Type: parquet.Int32Type, RepetitionType: parquet.RepetitionOptional}
}

func (i *Int32OptionalField) Add(r {{.Type}}) {
	v := i.val(r)
	if v != nil {
		i.vals = append(i.vals, *v)
		i.defs = append(i.defs, 1)
	} else {
		i.defs = append(i.defs, 0)
	}
}

type Int64Field struct {
	RequiredNumField
	val func(r {{.Type}}) int64
}

func NewInt64Field(val func(r {{.Type}}) int64, col string) *Int64Field {
	return &Int64Field{
		val:              val,
		RequiredNumField: RequiredNumField{col: col},
	}
}

func (i *Int64Field) Schema() parquet.Field {
	return parquet.Field{Name: i.col, Type: parquet.Int64Type, RepetitionType: parquet.RepetitionRequired}
}

func (i *Int64Field) Add(r {{.Type}}) {
	i.vals = append(i.vals, i.val(r))
}

type Int64OptionalField struct {
	OptionalNumField
	val func(r {{.Type}}) *int64
}

func NewInt64OptionalField(val func(r {{.Type}}) *int64, col string) *Int64OptionalField {
	return &Int64OptionalField{
		val:              val,
		OptionalNumField: OptionalNumField{col: col},
	}
}

func (i *Int64OptionalField) Schema() parquet.Field {
	return parquet.Field{Name: i.col, Type: parquet.Int64Type, RepetitionType: parquet.RepetitionOptional}
}

func (i *Int64OptionalField) Add(r {{.Type}}) {
	v := i.val(r)
	if v != nil {
		i.vals = append(i.vals, *v)
		i.defs = append(i.defs, 1)
	} else {
		i.defs = append(i.defs, 0)
	}
}

type Uint64Field struct {
	RequiredNumField
	val func(r {{.Type}}) uint64
}

func NewUint64Field(val func(r {{.Type}}) uint64, col string) *Uint64Field {
	return &Uint64Field{
		val:              val,
		RequiredNumField: RequiredNumField{col: col},
	}
}

func (i *Uint64Field) Schema() parquet.Field {
	return parquet.Field{Name: i.col, Type: parquet.Uint64Type, RepetitionType: parquet.RepetitionRequired}
}

func (i *Uint64Field) Add(r {{.Type}}) {
	i.vals = append(i.vals, i.val(r))
}

type Uint64OptionalField struct {
	OptionalNumField
	val func(r {{.Type}}) *uint64
}

func NewUint64OptionalField(val func(r {{.Type}}) *uint64, col string) *Uint64OptionalField {
	return &Uint64OptionalField{
		val:              val,
		OptionalNumField: OptionalNumField{col: col},
	}
}

func (i *Uint64OptionalField) Schema() parquet.Field {
	return parquet.Field{Name: i.col, Type: parquet.Uint64Type, RepetitionType: parquet.RepetitionOptional}
}

func (i *Uint64OptionalField) Add(r {{.Type}}) {
	v := i.val(r)
	if v != nil {
		i.vals = append(i.vals, *v)
		i.defs = append(i.defs, 1)
	} else {
		i.defs = append(i.defs, 0)
	}
}

type Float32Field struct {
	RequiredNumField
	val func(r {{.Type}}) float32
}

func NewFloat32Field(val func(r {{.Type}}) float32, col string) *Float32Field {
	return &Float32Field{
		val:              val,
		RequiredNumField: RequiredNumField{col: col},
	}
}

func (i *Float32Field) Schema() parquet.Field {
	return parquet.Field{Name: i.col, Type: parquet.Float32Type, RepetitionType: parquet.RepetitionRequired}
}

func (i *Float32Field) Add(r {{.Type}}) {
	i.vals = append(i.vals, i.val(r))
}

type Float32OptionalField struct {
	OptionalNumField
	val func(r {{.Type}}) *float32
}

func NewFloat32OptionalField(val func(r {{.Type}}) *float32, col string) *Float32OptionalField {
	return &Float32OptionalField{
		val:              val,
		OptionalNumField: OptionalNumField{col: col},
	}
}

func (i *Float32OptionalField) Schema() parquet.Field {
	return parquet.Field{Name: i.col, Type: parquet.Float32Type, RepetitionType: parquet.RepetitionOptional}
}

func (i *Float32OptionalField) Add(r {{.Type}}) {
	v := i.val(r)
	if v != nil {
		i.vals = append(i.vals, *v)

		i.defs = append(i.defs, 1)
	} else {
		i.defs = append(i.defs, 0)
	}
}

type BoolOptionalField struct {
	vals []bool
	defs []int64
	col  string
	val  func(r {{.Type}}) *bool
}

func NewBoolOptionalField(val func(r {{.Type}}) *bool, col string) *BoolOptionalField {
	return &BoolOptionalField{
		val: val,
		col: col,
	}
}

func (f *BoolOptionalField) Schema() parquet.Field {
	return parquet.Field{Name: f.col, Type: parquet.BoolType, RepetitionType: parquet.RepetitionOptional}
}

func (f *BoolOptionalField) Add(r {{.Type}}) {
	v := f.val(r)
	if v != nil {
		f.vals = append(f.vals, *v)
		f.defs = append(f.defs, 1)
	} else {
		f.defs = append(f.defs, 0)
	}
}

func (f *BoolOptionalField) Write(w io.Writer, meta *parquet.Metadata, pos int) error {
	buf := bytes.Buffer{}
	wc := &WriteCounter{w: &buf}

	err := WriteLevels(wc, f.defs)
	if err != nil {
		return err
	}

	ln := len(f.vals)
	byteNum := (ln + 7) / 8
	rawBuf := make([]byte, byteNum)

	for i := 0; i < ln; i++ {
		if f.vals[i] {
			rawBuf[i/8] = rawBuf[i/8] | (1 << uint32(i%8))
		}
	}

	wc.Write(rawBuf)

	compressed := snappy.Encode(nil, buf.Bytes())
	if err := meta.WritePageHeader(w, f.col, pos, wc.n, len(compressed), len(f.defs)); err != nil {
		return err
	}

	_, err = io.Copy(w, bytes.NewBuffer(compressed))
	return err
}

type StringField struct {
	vals []string
	col  string
	val  func(r {{.Type}}) string
}

func NewStringField(val func(r {{.Type}}) string, col string) *StringField {
	return &StringField{
		val: val,
		col: col,
	}
}

func (f *StringField) Schema() parquet.Field {
	return parquet.Field{Name: f.col, Type: parquet.StringType, RepetitionType: parquet.RepetitionRequired}
}

func (f *StringField) Add(r {{.Type}}) {
	f.vals = append(f.vals, f.val(r))
}

func (f *StringField) Write(w io.Writer, meta *parquet.Metadata, pos int) error {
	buf := bytes.Buffer{}
	wc := &WriteCounter{w: &buf}

	for _, s := range f.vals {
		if err := binary.Write(wc, binary.LittleEndian, int32(len(s))); err != nil {
			return err
		}
		wc.Write([]byte(s))
	}

	compressed := snappy.Encode(nil, buf.Bytes())
	if err := meta.WritePageHeader(w, f.col, pos, wc.n, len(compressed), len(f.vals)); err != nil {
		return err
	}

	_, err := io.Copy(w, bytes.NewBuffer(compressed))
	return err
}

type StringOptionalField struct {
	vals []string
	defs []int64
	col  string
	val  func(r {{.Type}}) *string
}

func NewStringOptionalField(val func(r {{.Type}}) *string, col string) *StringOptionalField {
	return &StringOptionalField{
		val: val,
		col: col,
	}
}

func (f *StringOptionalField) Schema() parquet.Field {
	return parquet.Field{Name: f.col, Type: parquet.StringType, RepetitionType: parquet.RepetitionOptional}
}

func (f *StringOptionalField) Add(r {{.Type}}) {
	v := f.val(r)
	if v != nil {
		f.vals = append(f.vals, *v)
		f.defs = append(f.defs, 1)
	} else {
		f.defs = append(f.defs, 0)
	}
}

func (f *StringOptionalField) Write(w io.Writer, meta *parquet.Metadata, pos int) error {
	buf := bytes.Buffer{}
	wc := &WriteCounter{w: &buf}

	err := WriteLevels(wc, f.defs)
	if err != nil {
		return err
	}

	for _, s := range f.vals {
		if err := binary.Write(wc, binary.LittleEndian, int32(len(s))); err != nil {
			return err
		}
		wc.Write([]byte(s))
	}

	compressed := snappy.Encode(nil, buf.Bytes())
	if err := meta.WritePageHeader(w, f.col, pos, wc.n, len(compressed), len(f.defs)); err != nil {
		return err
	}

	_, err = io.Copy(w, bytes.NewBuffer(compressed))
	return err
}

type WriteCounter struct {
	n int
	w io.Writer
}

func (w *WriteCounter) Write(p []byte) (int, error) {
	n, err := w.w.Write(p)
	w.n += n
	return n, err
}

// WriteLevels writes vals to w as RLE encoded data
func WriteLevels(w io.Writer, vals []int64) error {
	var max uint64
	if len(vals) > 0 {
		max = 1
	}

	rleBuf := writeRLE(vals, int32(bitNum(max)))
	res := make([]byte, 0)
	var lenBuf bytes.Buffer
	binary.Write(&lenBuf, binary.LittleEndian, int32(len(rleBuf)))
	res = append(res, lenBuf.Bytes()...)
	res = append(res, rleBuf...)
	_, err := io.Copy(w, bytes.NewBuffer(res))
	return err
}

func writeRLE(vals []int64, bitWidth int32) []byte {
	ln := len(vals)
	i := 0
	res := make([]byte, 0)
	for i < ln {
		j := i + 1
		for j < ln && vals[j] == vals[i] {
			j++
		}
		num := j - i
		header := num << 1
		byteNum := (bitWidth + 7) / 8

		headerBuf := writeUnsignedVarInt(uint64(header))

		var buf bytes.Buffer
		binary.Write(&buf, binary.LittleEndian, vals[i])
		valBuf := buf.Bytes()
		rleBuf := make([]byte, int64(len(headerBuf))+int64(byteNum))
		copy(rleBuf[0:], headerBuf)
		copy(rleBuf[len(headerBuf):], valBuf[0:byteNum])
		res = append(res, rleBuf...)
		i = j
	}
	return res
}

func writeUnsignedVarInt(num uint64) []byte {
	byteNum := (bitNum(uint64(num)) + 6) / 7
	if byteNum == 0 {
		return make([]byte, 1)
	}
	res := make([]byte, byteNum)

	numTmp := num
	for i := 0; i < int(byteNum); i++ {
		res[i] = byte(numTmp & uint64(0x7F))
		res[i] = res[i] | byte(0x80)
		numTmp = numTmp >> 7
	}
	res[byteNum-1] &= byte(0x7F)
	return res
}

func bitNum(num uint64) uint64 {
	var bitn uint64 = 0
	for ; num != 0; num >>= 1 {
		bitn++
	}
	return bitn
}`
